{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np \n",
    "from allennlp.data.token_indexers import TokenIndexer\n",
    "from allennlp.data.tokenizers import Token \n",
    "from allennlp.data.vocabulary import Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.data.tokenizers.word_tokenizer import WordTokenizer\n",
    "from allennlp.modules.token_embedders import Embedding\n",
    "from allennlp.modules.text_field_embedders import TextFieldEmbedder \n",
    "from allennlp.modules.seq2seq_encoders import Seq2SeqEncoder, PytorchSeq2SeqWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.training.trainer import Trainer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "path = Path('Lesson11/data/translate')\n",
    "en_path = path/'europarlv7-en-fr.en'\n",
    "fr_path = path/'europarlv7-fr-en.fr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "re_eq = re.compile('^(Wh[^?.!]+\\?)')\n",
    "re_fq = re.compile('^([^?.!]+\\?)')\n",
    "\n",
    "lines = ((re_eq.search(eq), re_fq.search(fq)) \n",
    "         for eq, fq in zip(open(en_path, encoding='utf-8'), open(fr_path, encoding='utf-8')))\n",
    "\n",
    "qs = [(e.group(), f.group()) for e,f in lines if e and f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Why has no air quality test been done on this particular building since we were elected?',\n",
       "  \"Comment se fait-il qu'aucun test de qualité de l'air n'ait été réalisé dans ce bâtiment depuis notre élection ?\"),\n",
       " ('Why has there been no Health and Safety Committee meeting since 1998?',\n",
       "  \"Comment se fait-il que le comité de santé et d'hygiène ne se soit plus réuni depuis 1998 ?\"),\n",
       " ('Why has there been no fire drill, either in the Brussels Parliament buildings or the Strasbourg Parliament buildings?',\n",
       "  \"Comment se fait-il que nous n'ayons jamais fait d'exercice d'évacuation dans les bâtiments du Parlement de Bruxelles et de Strasbourg ?\"),\n",
       " ('Why are there no fire instructions?',\n",
       "  \"Comment se fait-il qu'il n'y ait pas de consignes en cas d'incendie ?\"),\n",
       " ('Why have the staircases not been improved since my accident?',\n",
       "  \"Comment se fait-il que les escaliers n'aient pas été améliorés depuis mon accident ?\")]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs[:5] # en-fr questions as pairs in a tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(qs, (path/'fr-en-qs.pkl').open('wb'))\n",
    "qs = pickle.load((path/'fr-en-qs.pkl').open('rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_qs, fr_qs = zip(*qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tok = WordTokenizer().batch_tokenize(list(en_qs))  # return each sentence as a list of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_tok = WordTokenizer().batch_tokenize(list(fr_qs))  # return each sentence as a list of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14803 14803\n"
     ]
    }
   ],
   "source": [
    "print(len(en_tok), len(fr_tok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.0 34.0\n"
     ]
    }
   ],
   "source": [
    "print(np.percentile([len(o) for o in en_tok], 90),\n",
    "np.percentile([len(o) for o in fr_tok], 90))\n",
    "keep = np.array([len(o)<35 for o in en_tok])\n",
    "en_tok = np.array(en_tok)[keep]\n",
    "fr_tok = np.array(fr_tok)[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13683 13683\n"
     ]
    }
   ],
   "source": [
    "print(len(en_tok), len(fr_tok))  # total number of question pairs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vocabulary by mapping strings to integers \n",
    "# include only frequently occuring words in vocabulary \n",
    "import collections\n",
    "def toks2ids(tok,pre):\n",
    "    freq = collections.Counter(p for o in tok for p in o)\n",
    "    itos = [o for o,c in freq.most_common(40000)]\n",
    "    itos.insert(0, '_bos_')\n",
    "    itos.insert(1, '_pad_')\n",
    "    itos.insert(2, '_eos_')\n",
    "    itos.insert(3, '_unk')\n",
    "    stoi = collections.defaultdict(lambda: 3, \n",
    "                                   {v:k for k,v in enumerate(itos)})\n",
    "    ids = np.array([([stoi[o] for o in p] + [2]) for p in tok])\n",
    "    np.save(path/f'{pre}_ids.npy', ids)\n",
    "    # pickle.dump(itos, open(path/f'{pre}_itos.pkl', 'wb'))\n",
    "    return ids,itos,stoi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_ids,en_itos,en_stoi = toks2ids(en_tok,'en')\n",
    "fr_ids,fr_itos,fr_stoi = toks2ids(fr_tok,'fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([Comment,\n",
       "  se,\n",
       "  fait,\n",
       "  -,\n",
       "  il,\n",
       "  qu'aucun,\n",
       "  test,\n",
       "  de,\n",
       "  qualité,\n",
       "  de,\n",
       "  l'air,\n",
       "  n'ait,\n",
       "  été,\n",
       "  réalisé,\n",
       "  dans,\n",
       "  ce,\n",
       "  bâtiment,\n",
       "  depuis,\n",
       "  notre,\n",
       "  élection,\n",
       "  ?,\n",
       "  '_eos_'],\n",
       " 40004,\n",
       " 40004)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[fr_itos[o] for o in fr_ids[0]], len(fr_itos), len(en_itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install git+https://github.com/facebookresearch/fastText.git\n",
    "import fastText as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sq2sqDataset(x, y):\n",
    "    def __init__(self, x, y): \n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    def __getitem__(self, idx):\n",
    "        return A(self.x[idx], self.y[idx])\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sq2sq(nn.Module):\n",
    "    super.__init__():\n",
    "        def\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
